{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96438edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f5106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take url as input and verify it\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def is_valid_reddit_user_url(url: str):\n",
    "\n",
    "    pattern = r\"^https?://(www\\.)?reddit\\.com/user/[A-Za-z0-9_-]+/?$\"\n",
    "    return re.match(pattern, url.strip()) is not None\n",
    "\n",
    "def extract_username_from_url(url: str):\n",
    "\n",
    "    if is_valid_reddit_user_url(url):\n",
    "        return url.strip(\"/\").split(\"/\")[-1]\n",
    "    return None\n",
    "\n",
    "input_url = input(\"Enter Url\")\n",
    "url = is_valid_reddit_user_url(input_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fe58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data extraction using webbaseloader\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from typing import List\n",
    "\n",
    "\n",
    "if url:\n",
    "    loader = WebBaseLoader(web_path=(url,))\n",
    "    data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "580c3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into chunks\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=0)\n",
    "docs = splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the the data into vectoredb\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model=\"all-MiniLM-L6-V2\")\n",
    "\n",
    "vectorestore = Chroma.from_documents(documents=docs, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever to access database\n",
    "\n",
    "retriever=vectorestore.as_retriever(search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e831785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt \n",
    "\n",
    "system_prompt = \"\"\" \n",
    "\n",
    "You aree a helpful AI that builds detailed user personas from reddit data.\n",
    "The information you retrieve includes Reddit comments written by a specific user.\n",
    "Based on this content, extrac:\n",
    "- Personal Information\n",
    "- Motivations\n",
    "- Personality\n",
    "- Behaviour and Habits\n",
    "- Goals and needs\n",
    "- Frustrations\n",
    "\n",
    "For each characteristic in the user persona, the script also “cites” the\n",
    "comments it used to extract the specific user persona information.\n",
    "\n",
    "Use a reddit text as evidence for each characteristic. write the persona in structured format like this:\n",
    "[User Persona]\n",
    "- Personal Information : It includes Age, Occupation, Status, Location, Tier, Archetype.. etc.\n",
    "- Motivations : it includes convenience, speed, wellness, preferences, comfort, dietary needs..etc eith percentage.\n",
    "- Personality : it includes introvert or extrovert, intuition or sensing,feeling or thinking, perceiving or judging,..etc with percentage.\n",
    "- Behaviour and Habits : describe with 3 - 4 bullet points (cite the comment)\n",
    "- Goals and needs : describe with 3 - 4 bullet points (cite the comment)\n",
    "- Frustrations : describe with 3 - 4 bullet points (cite the comment)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd65e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and store the persona in the response variable\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt ),\n",
    "    (\"user\", \"Generate a complete user persona using the retrieved Reddit data.\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = rag_chain.run(\"Generate a user persona.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the response into txt file\n",
    "\n",
    "\n",
    "with open(\"persona.txt\",'w',encoding='utf-8') as f:\n",
    "    f.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
